{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Grap a GPU\n",
        "\n",
        "Before doing anything, let's try to get a GPU instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Go to instance's option:\n",
        "\n",
        "![step_0](https://raw.githubusercontent.com/theostos/small-pytanque-tp/refs/heads/main/img/step_0_option.png)\n",
        "\n",
        "Change runtime\n",
        "\n",
        "![step_1](https://raw.githubusercontent.com/theostos/small-pytanque-tp/refs/heads/main/img/step_1_change_runtime.png)\n",
        "\n",
        "Add T4 GPU\n",
        "\n",
        "![step_2](https://raw.githubusercontent.com/theostos/small-pytanque-tp/refs/heads/main/img/step_2_t4.png)\n",
        "\n",
        "Then connect to a GPU instance\n",
        "\n",
        "![step_3](https://raw.githubusercontent.com/theostos/small-pytanque-tp/refs/heads/main/img/step_3_connect.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEITjNO2R8ZW"
      },
      "source": [
        "### Environment setup\n",
        "\n",
        "This first cell needs to be executed to set up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0vAA7TYPiou",
        "outputId": "f9bfbb53-a733-49fc-ed25-8e23831c47ef"
      },
      "outputs": [],
      "source": [
        "%pip install ollama\n",
        "%pip install colab-xterm\n",
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install pciutils lshw\n",
        "\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "url = \"https://raw.githubusercontent.com/theostos/small-pytanque-tp/refs/heads/main/client.py\"\n",
        "!wget --no-cache --backups=1 {url}\n",
        "url = \"https://raw.githubusercontent.com/theostos/small-pytanque-tp/refs/heads/main/utils.py\"\n",
        "!wget --no-cache --backups=1 {url}\n",
        "!pip install requests\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following cell instantiate a client to connect to Rocq proof assistant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from client import ProofAssistantClientAPI, goals_to_str\n",
        "\n",
        "client = ProofAssistantClientAPI(\"http://128.93.101.129:8765\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICLmivdZSdHP"
      },
      "source": [
        "On the server side, there is a file containing some theorems. First, let's look at them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMwUUyZPQVrN",
        "outputId": "67ef1f96-7a82-41f3-a2b5-d0e89fd647bd"
      },
      "outputs": [],
      "source": [
        "for section in client.sections():\n",
        "  print(f\"Theorems in section: {section}\")\n",
        "  for k in range(client.num_thm(section)):\n",
        "    thm = client.show_thm(section, k)\n",
        "    print(f\"Theorem {k}, {thm['name']} description: {thm['statement']}\")\n",
        "  print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A case study: Lelarge's Theorem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W100hytLR3ZJ"
      },
      "source": [
        "We will start by proving the Lelarge's Theorem in the Introduction section.\n",
        "Let's review it by selecting the first theorem (index = 0) in the \"introduction\" section.\n",
        "\n",
        "Before doing so, we need to examine the current context (i.e. the available lemmas, definitions, and notations) to understand it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNj_IITFRW22",
        "outputId": "f44c297a-d83a-487a-e1f1-0a6ba6cbbe4e"
      },
      "outputs": [],
      "source": [
        "thm =  client.show_thm(\"introduction\", 0)\n",
        "print(\"Context:\")\n",
        "print(\"\\n\".join(thm['premises']))\n",
        "print(\"\\n\")\n",
        "print(f\"Theorem {thm['name']}: {thm['statement']}\",)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Theorem involution_injective states that an arbitrary function f, satisfying Hinv (i.e. being an involution), is one-to-one.\n",
        "\n",
        "To prove it, we will use the following tactics (read from left to right):\n",
        "\n",
        "* \"intros x y H.\" introduces two variables, x and y, associated with the forall quantifier, and the hypothesis H corresponding to f x = f y.\n",
        "* \"rewrite <- Hinv with (x := x).\" rewrites the left-hand side of the current goal using the hypothesis specialized with x = x.\n",
        "* \"rewrite <- Hinv with (x := y).\" rewrites the left-hand side of the current goal using the hypothesis specialized with x = y.\n",
        "* \"rewrite H.\" rewrites the current goal using the introduced hypothesis H (i.e. f x = f y).\n",
        "* \"reflexivity.\" discharges goals of the form a = a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state, goals = client.start_thm(\"introduction\", 0)\n",
        "print(\"Started theorem session:\")\n",
        "print(goals_to_str(goals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state, goals = client.run_tac(state, \"intros x y H.\")\n",
        "print(goals_to_str(goals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state, goals = client.run_tac(state, \"rewrite <- Hinv with (x := x).\")\n",
        "print(goals_to_str(goals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state, goals = client.run_tac(state, \"rewrite <- Hinv with (x := y).\")\n",
        "print(goals_to_str(goals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state, goals = client.run_tac(state, \"rewrite H.\")\n",
        "print(goals_to_str(goals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state, goals = client.run_tac(state, \"reflexivity.\")\n",
        "print(goals_to_str(goals))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Automation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sledge Hammer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try to automate theorem proving. In deep learning our sledge hammer is big LLM, and one of them is chatGPT.\n",
        "Is it able to prove Lelarge's theorem?\n",
        "\n",
        "First, let's ask it to one of the best \"reasoning\" model: GPT o3-mini.\n",
        "Extract the sequence of tactics from [this](https://chatgpt.com/share/67e9842e-7d18-8007-b394-d29b03d859cb) link, and try to submit it to the Rocq server ([petanque server](https://github.com/ejgallego/coq-lsp/tree/main/petanque)).\n",
        "\n",
        "To do it, complete the following cell. You only need to add the remaining tactics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# complete the following list with the sequence of tactics provided by GPT o3-mini\n",
        "tactics = ['intros x y H.'] # ['intros x y H.', 'tactic_1', 'tactic_2', 'and so on']\n",
        "\n",
        "state, goals = client.start_thm(\"introduction\", 0)\n",
        "\n",
        "for tactic in tactics:\n",
        "    state, goals = client.run_tac(state, tactic)\n",
        "    print(goals_to_str(goals))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remarkably, if we ask more modest model things get a bit more complex:\n",
        "* Asking to GPT 4o model (see [here](https://chatgpt.com/share/67e986d3-6650-8007-b01c-b5dfe48468a5)), it is able to prove it after 5 attempts.\n",
        "* Asking to GPT 4o-mini (see [here](https://chatgpt.com/share/67e9871d-9de8-8007-aaeb-04d48d61b525)) is not able to prove it in 8 attempts.\n",
        "\n",
        "And even more remarkably, both non reasoning and reasoning model from [DeepSeek](https://chat.deepseek.com/) are able to solve this problem at the first attempt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Open-weight model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's try to do it with an open-weight locally run model. We choose Gemma 3 12b, since it has good performance while being able to run on a collab T4 instance.\n",
        "\n",
        "First we need to start an inference engine (to serve our model locally)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "subprocess.Popen([\"ollama\", \"serve\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, let's download gemma 3 12b."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ollama pull gemma3:12b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To use the model, we will simply call the function get_reponse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import get_response\n",
        "\n",
        "prompt = \"Why the sky is blue?\"\n",
        "\n",
        "print(get_response(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's try to prove simple Rocq lemma (section \"logic\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def parse_output(output):\n",
        "    \"\"\"\n",
        "    Function to parse LLM output.\n",
        "    It expects outputs with the following format\n",
        "    ```coq\n",
        "    tactic.\n",
        "    ```\n",
        "    \"\"\"\n",
        "    # to avoid some parsing issue, we accept instruction to not end with a point as normally required.\n",
        "    pattern = r'```coq\\n(.*?)\\.?\\n'\n",
        "    match_output = re.search(pattern, output)\n",
        "    if match_output:\n",
        "      output = match_output.group(1).strip()\n",
        "      return output + '.'\n",
        "    return ''\n",
        "\n",
        "prompt_template = \"\"\"You are an expert in Coq, a theorem-proving assistant. Your task is to help progress a formal proof by providing exactly one correct and effective Coq tactic to advance towards the goal.\n",
        "Current proof state:\n",
        "{goal}\n",
        "\n",
        "Carefully analyze the current goal, consider available hypotheses, and propose the most logical and efficient next step in the proof.\n",
        "\n",
        "Respond with ONLY ONE Coq tactic enclosed in a Coq code block. Ensure the tactic is syntactically correct and directly applicable. Don't write any comment, simple the code block.\n",
        "\n",
        "Example of correct formatting:\n",
        "```coq\n",
        "tactic_1.\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "for idx in range(client.num_thm('logic')):\n",
        "  print(f\"Try to prove theorem {idx}\")\n",
        "  state, goals = client.start_thm(\"logic\", idx)\n",
        "\n",
        "  for _ in range(100):\n",
        "    to_prove_pp = goals_to_str(goals)\n",
        "\n",
        "    # Gemma3 seems to prefer natural language instead of weird logician symbols\n",
        "    to_prove = to_prove_pp.replace('|-', 'to prove: ')\n",
        "\n",
        "    prompt = prompt_template.format(goal=to_prove)\n",
        "    output = get_response(prompt)\n",
        "    next_tactic = parse_output(output)\n",
        "\n",
        "    try:\n",
        "      state, goals = client.run_tac(state, next_tactic)\n",
        "      print(next_tactic)\n",
        "    except Exception as e:\n",
        "      print(\"Wrong tactic.\")\n",
        "      pass\n",
        "    if not goals:\n",
        "      print(\"success!\")\n",
        "      break  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gemma3 seems to make a lot of mistakes.\n",
        "You may try to improve the prompt.\n",
        "\n",
        "In the following cell, there is a prompt with an explanation of some tactics in Rocq, try it to see if it makes any difference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"You are an expert in Coq, a theorem-proving assistant. Your task is to help progress a formal proof by providing exactly one correct and effective Coq tactic to advance towards the goal.\n",
        "\n",
        "Here is a brief explanation of tactics you may use:\n",
        "\n",
        "- intros: Introduces hypotheses or variables into the context. (example: \"intros P Q.\" introduces hypotheses P and Q.)\n",
        "- apply: Applies a hypothesis or theorem to match the current goal. (example: \"apply H0.\" If the goal is Q and you have a hypothesis H0: P -> Q, applying H0 changes the goal to P.)\n",
        "- exact: Directly solves the current goal if you have an exact matching hypothesis. (example: \"exact H.\" If the goal is P and you have a hypothesis H: P, then the goal is resolved.)\n",
        "- contradiction: Resolves the goal if there is a contradiction in the hypotheses. (example: if you have hypotheses H1: P -> False and H2: P, using \"contradiction.\" resolves the goal.)\n",
        "- unfold not: Expands the definition of negation (~P becomes P -> False). (examples: \"unfold not in H.\" applies it to hypothesis H, \"unfold not.\" applies it to the goal.)\n",
        "- inversion: Breaks apart hypotheses involving conjunctions (and), disjunctions (or), or existential quantifiers to reveal simpler components. (example: \"inversion H.\" breaks hypothesis H into simpler parts.)\n",
        "- split: Splits goals involving conjunctions into separate subgoals. (example: \"split.\" transforms goal P /\\ Q into two separate goals, P and Q.)\n",
        "- left/right: Selects a side of a disjunction (or) goal to prove. (examples: \"left.\" to prove the left side of a goal P \\/ Q, \"right.\" to prove the right side.)\n",
        "\n",
        "Current proof state:\n",
        "{goal}\n",
        "\n",
        "Carefully analyze the current goal, consider available hypotheses, and propose the most logical and efficient next step in the proof.\n",
        "\n",
        "Respond with ONLY ONE Coq tactic enclosed in a Coq code block. Ensure the tactic is syntactically correct and directly applicable. Don't write any comment, simple the code block.\n",
        "\n",
        "Example of correct formatting:\n",
        "```coq\n",
        "tactic_1.\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "for idx in range(client.num_thm('logic')):\n",
        "  print(f\"Try to prove theorem {idx}\")\n",
        "  state, goals = client.start_thm(\"logic\", idx)\n",
        "\n",
        "  for _ in range(100):\n",
        "    to_prove_pp = goals_to_str(goals)\n",
        "\n",
        "    # Gemma3 seems to prefer natural language instead of weird logician symbols\n",
        "    to_prove = to_prove_pp.replace('|-', 'to prove: ')\n",
        "\n",
        "    prompt = prompt_template.format(goal=to_prove)\n",
        "    output = get_response(prompt)\n",
        "    next_tactic = parse_output(output)\n",
        "\n",
        "    try:\n",
        "      state, goals = client.run_tac(state, next_tactic)\n",
        "      print(next_tactic)\n",
        "    except Exception as e:\n",
        "      print(\"Wrong tactic generation.\")\n",
        "      pass\n",
        "    if not goals:\n",
        "      print(\"Success!\")\n",
        "      break  \n",
        "  print()\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This may not be enough. You could try the following strategies:\n",
        "- Increase the number of try.\n",
        "- Add some examples of lemma + proof in your prompt (few-shot prompting).\n",
        "\n",
        "If you feel confident enough, you could try to improve the overall strategy:\n",
        "- what would happens if you keep tracks of the wrong step in your prompt? (i.e. the one that throw an error)\n",
        "- what would happens if you keep tracks of step that leads you to an already visited goal?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find a better strategy/prompt!\n",
        "prompt_template = \"\"\"You are an expert in Coq, a theorem-proving assistant. Your task is to help progress a formal proof by providing exactly one correct and effective Coq tactic to advance towards the goal.\n",
        "\n",
        "Here is a brief explanation of tactics you may use:\n",
        "\n",
        "- intros: Introduces hypotheses or variables into the context. (example: \"intros P Q.\" introduces hypotheses P and Q.)\n",
        "- apply: Applies a hypothesis or theorem to match the current goal. (example: \"apply H0.\" If the goal is Q and you have a hypothesis H0: P -> Q, applying H0 changes the goal to P.)\n",
        "- exact: Directly solves the current goal if you have an exact matching hypothesis. (example: \"exact H.\" If the goal is P and you have a hypothesis H: P, then the goal is resolved.)\n",
        "- contradiction: Resolves the goal if there is a contradiction in the hypotheses. (example: if you have hypotheses H1: P -> False and H2: P, using \"contradiction.\" resolves the goal.)\n",
        "- unfold not: Expands the definition of negation (~P becomes P -> False). (examples: \"unfold not in H.\" applies it to hypothesis H, \"unfold not.\" applies it to the goal.)\n",
        "- inversion: Breaks apart hypotheses involving conjunctions (and), disjunctions (or), or existential quantifiers to reveal simpler components. (example: \"inversion H.\" breaks hypothesis H into simpler parts.)\n",
        "- split: Splits goals involving conjunctions into separate subgoals. (example: \"split.\" transforms goal P /\\ Q into two separate goals, P and Q.)\n",
        "- left/right: Selects a side of a disjunction (or) goal to prove. (examples: \"left.\" to prove the left side of a goal P \\/ Q, \"right.\" to prove the right side.)\n",
        "\n",
        "Current proof state:\n",
        "{goal}\n",
        "\n",
        "Carefully analyze the current goal, consider available hypotheses, and propose the most logical and efficient next step in the proof.\n",
        "\n",
        "Respond with ONLY ONE Coq tactic enclosed in a Coq code block. Ensure the tactic is syntactically correct and directly applicable. Don't write any comment, simple the code block.\n",
        "\n",
        "Example of correct formatting:\n",
        "```coq\n",
        "tactic_1.\n",
        "```\n",
        "\"\"\"\n",
        "for idx in range(client.num_thm('logic')):\n",
        "  print(f\"Try to prove theorem {idx}\")\n",
        "  state, goals = client.start_thm(\"logic\", idx)\n",
        "\n",
        "  for _ in range(100):\n",
        "    to_prove_pp = goals_to_str(goals)\n",
        "\n",
        "    # Gemma3 seems to prefer natural language instead of weird logician symbols\n",
        "    to_prove = to_prove_pp.replace('|-', 'to prove: ')\n",
        "\n",
        "    prompt = prompt_template.format(goal=to_prove)\n",
        "    output = get_response(prompt)\n",
        "    next_tactic = parse_output(output)\n",
        "\n",
        "    try:\n",
        "      state, goals = client.run_tac(state, next_tactic)\n",
        "      print(next_tactic)\n",
        "    except Exception as e:\n",
        "      print(\"Wrong tactic generation.\")\n",
        "      pass\n",
        "    if not goals:\n",
        "      print(\"Success!\")\n",
        "      break  \n",
        "  print()\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following cell, you will find an implementation that is a bit better (keep track of errors and redundant tactics)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "prompt_template = \"\"\"You are an expert in Coq, a theorem-proving assistant. Your task is to help progress a formal proof by providing exactly one correct and effective Coq tactic to advance towards the goal.\n",
        "\n",
        "Here is a brief explanation of tactics you may use:\n",
        "\n",
        "- intros: Introduces hypotheses or variables into the context. (example: \"intros P Q.\" introduces hypotheses P and Q.)\n",
        "- apply: Applies a hypothesis or theorem to match the current goal. (example: \"apply H0.\" If the goal is Q and you have a hypothesis H0: P -> Q, applying H0 changes the goal to P.)\n",
        "- exact: Directly solves the current goal if you have an exact matching hypothesis. (example: \"exact H.\" If the goal is P and you have a hypothesis H: P, then the goal is resolved.)\n",
        "- contradiction: Resolves the goal if there is a contradiction in the hypotheses. (example: if you have hypotheses H1: P -> False and H2: P, using \"contradiction.\" resolves the goal.)\n",
        "- unfold not: Expands the definition of negation (~P becomes P -> False). (examples: \"unfold not in H.\" applies it to hypothesis H, \"unfold not.\" applies it to the goal.)\n",
        "- inversion: Breaks apart hypotheses involving conjunctions (and), disjunctions (or), or existential quantifiers to reveal simpler components. (example: \"inversion H.\" breaks hypothesis H into simpler parts.)\n",
        "- split: Splits goals involving conjunctions into separate subgoals. (example: \"split.\" transforms goal P /\\ Q into two separate goals, P and Q.)\n",
        "- left/right: Selects a side of a disjunction (or) goal to prove. (examples: \"left.\" to prove the left side of a goal P \\/ Q, \"right.\" to prove the right side.)\n",
        "\n",
        "Current proof state:\n",
        "{goal}\n",
        "\n",
        "Carefully analyze the current goal, consider available hypotheses, and propose the most logical and efficient next step in the proof.\n",
        "\n",
        "Respond with ONLY ONE Coq tactic enclosed in a Coq code block. Ensure the tactic is syntactically correct and directly applicable. Don't write any comment, simple the code block.\n",
        "\n",
        "Example of correct formatting:\n",
        "```coq\n",
        "tactic_1.\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "prompt_remove = \"\"\"Don't use any of the following instructions:\n",
        "{remove}\n",
        "\"\"\"\n",
        "\n",
        "success = False\n",
        "for idx in range(client.num_thm('logic')):\n",
        "  print(f\"Try to prove theorem {idx}\")\n",
        "  state, goals = client.start_thm(\"logic\", idx)\n",
        "  tactics = []\n",
        "  useless_tactics = defaultdict(list)\n",
        "  failed_tactics = []\n",
        "  for _ in range(100):\n",
        "    to_prove_pp = goals_to_str(goals)\n",
        "    to_prove = to_prove_pp.replace('|-', 'to prove: ')\n",
        "\n",
        "    prompt = prompt_template.format(goal=to_prove)\n",
        "    if failed_tactics:\n",
        "      prompt += prompt_remove.format(remove=\"\\n\".join(failed_tactics))\n",
        "    \n",
        "    if useless_tactics[to_prove_pp]:\n",
        "      prompt += prompt_remove.format(remove=\"\\n\".join(useless_tactics[to_prove_pp]))\n",
        "  \n",
        "    output = get_response(prompt)\n",
        "    next_tactic = parse_output(output)\n",
        "    try:\n",
        "      state, goals = client.run_tac(state, next_tactic)\n",
        "      new_to_prove_pp = goals_to_str(goals)\n",
        "      if to_prove_pp == new_to_prove_pp:\n",
        "        useless_tactics[new_to_prove_pp].append(next_tactic)\n",
        "      print(next_tactic)\n",
        "      tactics.append(next_tactic)\n",
        "      failed_tactics = []\n",
        "    except Exception as e:\n",
        "      failed_tactics.append(next_tactic)\n",
        "      pass\n",
        "    if not goals:\n",
        "      print(\"Finished!\")\n",
        "      print(\"Found solution:\\n\" + \"\\n\".join(tactics))\n",
        "      break\n",
        "  if goals:\n",
        "    print(\"Failed\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specialized open-weight model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's download [ProofWala](https://arxiv.org/abs/2502.04671), a finetuned version of [Code T5](https://arxiv.org/abs/2109.00859) model on a dataset of Lean and Rocq proofs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from transformers import pipeline\n",
        "from functools import partial\n",
        "from utils import generate_tactics_wala\n",
        "\n",
        "model_name = \"amitayusht/ProofWala-Multilingual\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0) # device=0 for GPU, -1 for CPU\n",
        "\n",
        "generate_tactics = partial(generate_tactics_wala, pipeline, model, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's try this new model on previous lemmas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "steps = []\n",
        "incorrect_steps = []\n",
        "\n",
        "for idx in range(client.num_thm('logic')):\n",
        "  print(f\"Try to prove theorem {idx}\")\n",
        "  state, goals = client.start_thm(\"logic\", idx)\n",
        "\n",
        "  for _ in range(100):\n",
        "    # generate 1 candidate for the next step associated to goals, and given previous steps and incorrect_steps\n",
        "    tactics, _ = generate_tactics(1, goals, steps=steps, incorrect_steps=incorrect_steps)\n",
        "    next_tactic = tactics[0]\n",
        "    try:\n",
        "      state, goals = client.run_tac(state, next_tactic)\n",
        "      print(next_tactic)\n",
        "      steps.append(next_tactic)\n",
        "      # reset incorrect steps\n",
        "      incorrect_steps = []\n",
        "    except Exception as e:\n",
        "      print(\"Wrong tactic generation.\")\n",
        "      incorrect_steps.append(next_tactic)\n",
        "      pass\n",
        "    if not goals:\n",
        "      print(\"success!\")\n",
        "      break  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, what would happen with a beam search (step-wise)? Let's try it on our whole collection of exercises."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m beam_search\n\u001b[32m      3\u001b[39m NUM_TRY = \u001b[32m30\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m section \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mintroduction\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlogic\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmath\u001b[39m\u001b[33m'\u001b[39m]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/small-pytanque-tp/utils.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mollama\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProofAssistantClientAPI, goals_to_str\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "from utils import beam_search\n",
        "\n",
        "NUM_TRY = 30\n",
        "for section in ['introduction', 'logic', 'math']:\n",
        "    for idx_thm in range(client.num_thm(section)):\n",
        "        print(f\"Trying to prove theorem {idx_thm} in section {section}.\")\n",
        "        for _ in range(NUM_TRY):\n",
        "            result = beam_search(generate_tactics, client, section, idx_thm, max_depth=7, beam_size=32, timeout=60)\n",
        "            if result:\n",
        "                print(\"Solution found:\")\n",
        "                print(\"\\n\".join(result))\n",
        "                print()\n",
        "                print()\n",
        "                break\n",
        "            else:\n",
        "                print(\"FAILED\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "flask_new",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
