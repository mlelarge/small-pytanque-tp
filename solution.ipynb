{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Grap a GPU\n",
        "\n",
        "(Google Colab only)\n",
        "\n",
        "Before doing anything, let's try to get a GPU instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Go to instance options\n",
        "\n",
        "![step_0](https://raw.githubusercontent.com/theostos/small-pytanque-tp/refs/heads/main/img/step_0_option.png)\n",
        "\n",
        "Change runtime\n",
        "\n",
        "![step_1](https://raw.githubusercontent.com/theostos/small-pytanque-tp/refs/heads/main/img/step_1_change_runtime.png)\n",
        "\n",
        "Add T4 GPU\n",
        "\n",
        "![step_2](https://raw.githubusercontent.com/theostos/small-pytanque-tp/refs/heads/main/img/step_2_t4.png)\n",
        "\n",
        "Then connect to a GPU instance\n",
        "\n",
        "![step_3](https://raw.githubusercontent.com/theostos/small-pytanque-tp/refs/heads/main/img/step_3_connect.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEITjNO2R8ZW"
      },
      "source": [
        "### Environment setup\n",
        "\n",
        "This first cell needs to be executed to set up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0vAA7TYPiou",
        "outputId": "f9bfbb53-a733-49fc-ed25-8e23831c47ef"
      },
      "outputs": [],
      "source": [
        "%pip install ollama\n",
        "%pip install colab-xterm\n",
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install pciutils lshw\n",
        "\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "url = \"https://raw.githubusercontent.com/theostos/small-pytanque-tp/refs/heads/main/client.py\"\n",
        "!wget --no-cache --backups=1 {url}\n",
        "url = \"https://raw.githubusercontent.com/theostos/small-pytanque-tp/refs/heads/main/utils.py\"\n",
        "!wget --no-cache --backups=1 {url}\n",
        "!pip install requests\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following cell instantiates a client to connect to the Rocq proof assistant.\n",
        "Don't forget to change the IP_ADDRESS constant!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "IP_ADDRESS = \"http://128.93.101.129:8765\"\n",
        "\n",
        "from client import ProofAssistantClientAPI, goals_to_str\n",
        "\n",
        "client = ProofAssistantClientAPI(IP_ADDRESS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICLmivdZSdHP"
      },
      "source": [
        "On the server side, there is a file containing some theorems. First, let's look at them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMwUUyZPQVrN",
        "outputId": "67ef1f96-7a82-41f3-a2b5-d0e89fd647bd"
      },
      "outputs": [],
      "source": [
        "for section in client.sections():\n",
        "  print(f\"Theorems in section: {section}\")\n",
        "  for k in range(client.num_thm(section)):\n",
        "    thm = client.show_thm(section, k)\n",
        "    print(f\"Theorem {k}, {thm['name']} description: {thm['statement']}\")\n",
        "  print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A case study: Lelarge's Theorem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W100hytLR3ZJ"
      },
      "source": [
        "We will start by proving Lelarge's Theorem in the Introduction section.\n",
        "Let's review it by selecting the first theorem (index = 0) in the \"introduction\" section.\n",
        "\n",
        "Before doing so, we need to examine the current context (i.e. the available lemmas, definitions, and notations) to understand it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNj_IITFRW22",
        "outputId": "f44c297a-d83a-487a-e1f1-0a6ba6cbbe4e"
      },
      "outputs": [],
      "source": [
        "thm =  client.show_thm(\"introduction\", 0)\n",
        "print(\"Context:\")\n",
        "print(\"\\n\".join(thm['premises']))\n",
        "print(\"\\n\")\n",
        "print(f\"Theorem {thm['name']}: {thm['statement']}\",)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Theorem involution_injective states that an arbitrary function f, satisfying Hinv (i.e. being an involution), is one-to-one.\n",
        "\n",
        "To prove it, we will use the following tactics (read from left to right):\n",
        "\n",
        "* \"intros x y H.\" introduces two variables, x and y, associated with the forall quantifier, and the hypothesis H corresponding to f x = f y.\n",
        "* \"rewrite <- Hinv with (x := x).\" rewrites the left-hand side of the current goal using the hypothesis specialized with x = x.\n",
        "* \"rewrite <- Hinv with (x := y).\" rewrites the left-hand side of the current goal using the hypothesis specialized with x = y.\n",
        "* \"rewrite H.\" rewrites the current goal using the introduced hypothesis H (i.e. f x = f y).\n",
        "* \"reflexivity.\" discharges goals of the form a = a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state, goals = client.start_thm(\"introduction\", 0)\n",
        "print(\"Started theorem session:\")\n",
        "print(goals_to_str(goals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state, goals = client.run_tac(state, \"intros x y H.\")\n",
        "print(goals_to_str(goals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state, goals = client.run_tac(state, \"rewrite <- Hinv with (x := x).\")\n",
        "print(goals_to_str(goals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state, goals = client.run_tac(state, \"rewrite <- Hinv with (x := y).\")\n",
        "print(goals_to_str(goals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state, goals = client.run_tac(state, \"rewrite H.\")\n",
        "print(goals_to_str(goals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state, goals = client.run_tac(state, \"reflexivity.\")\n",
        "print(goals_to_str(goals))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Automation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ChatGPT vs Rocq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try to automate theorem proving. In deep learning, our sledgehammer is a big LLM, such as chatGPT.\n",
        "Is it able to prove Lelarge's theorem?\n",
        "\n",
        "First, let's ask it to one of the best \"reasoning\" models: GPT o3-mini.\n",
        "Extract the sequence of tactics from [this](https://chatgpt.com/share/67e9842e-7d18-8007-b394-d29b03d859cb) link, and try to submit it to the Rocq server ([petanque server](https://github.com/ejgallego/coq-lsp/tree/main/petanque)).\n",
        "\n",
        "To do it, complete the following cell. You only need to add the remaining tactics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# complete the following list with the sequence of tactics provided by GPT o3-mini\n",
        "tactics = ['intros x y H.', 'rewrite <- (Hinv x).', 'rewrite H.', 'rewrite Hinv.', 'reflexivity.'] # ['intros x y H.', 'tactic_1', 'tactic_2', 'and so on']\n",
        "\n",
        "state, goals = client.start_thm(\"introduction\", 0)\n",
        "\n",
        "for tactic in tactics:\n",
        "    state, goals = client.run_tac(state, tactic)\n",
        "    print(goals_to_str(goals))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remarkably, if we ask a more modest model, things get a bit more complex:\n",
        "* Asking to GPT 4o model (see [here](https://chatgpt.com/share/67e986d3-6650-8007-b01c-b5dfe48468a5)), it is able to prove it after 5 attempts.\n",
        "* Asking to GPT 4o-mini (see [here](https://chatgpt.com/share/67e9871d-9de8-8007-aaeb-04d48d61b525)) is not able to prove it in 8 attempts.\n",
        "\n",
        "And even more remarkably, both the non reasoning and reasoning model from [DeepSeek](https://chat.deepseek.com/) are able to solve this problem on the first attempt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Open-weight model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's try to do it with an open-weight, locally run model. We choose Gemma 3 12b, since it has good performance while being able to run on a colab T4 instance.\n",
        "\n",
        "First, we need to start an inference engine (to serve our model locally)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!while true; do nohup ollama serve >/dev/null 2>&1; sleep 1; done >/dev/null 2>&1 &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, let's download Gemma 3 12b."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ollama pull gemma3:12b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To use the model, we will simply call the function get_response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import get_response\n",
        "from tqdm import tqdm\n",
        "\n",
        "prompt = \"Why the sky is blue? Write a short answer.\"\n",
        "\n",
        "print(get_response(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's try to prove simple Rocq lemmas (section \"logic\").\n",
        "\n",
        "Complete the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def parse_output(output):\n",
        "    \"\"\"\n",
        "    Function to parse LLM output.\n",
        "    It expects outputs with the following format\n",
        "    ```coq\n",
        "    tactic.\n",
        "    ```\n",
        "    \"\"\"\n",
        "    # to avoid some parsing issue, we accept instruction to not end with a point as normally required.\n",
        "    pattern = r'```coq\\n(.*?)\\.?\\n'\n",
        "    match_output = re.search(pattern, output)\n",
        "    if match_output:\n",
        "      output = match_output.group(1).strip()\n",
        "      return output + '.'\n",
        "    return ''\n",
        "\n",
        "prompt_template = \"\"\"You are an expert in Coq, a theorem-proving assistant. Your task is to help progress a formal proof by providing exactly one correct and effective Coq tactic to advance towards the goal.\n",
        "Current proof state:\n",
        "{goal}\n",
        "\n",
        "Carefully analyze the current goal, consider available hypotheses, and propose the most logical and efficient next step in the proof.\n",
        "\n",
        "Respond with ONLY ONE Coq tactic enclosed in a Coq code block. Ensure the tactic is syntactically correct and directly applicable. Don't write any comment, simple the code block.\n",
        "\n",
        "Example of correct formatting:\n",
        "```coq\n",
        "tactic_1.\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "for idx in range(client.num_thm('logic')):\n",
        "  # iterate over all theorem in the section 'logic'\n",
        "\n",
        "  print(f\"Try to prove theorem {idx}\")\n",
        "  state, goals = client.start_thm(\"logic\", idx)\n",
        "  tactics = []\n",
        "  for _ in tqdm(range(25)):\n",
        "\n",
        "    # retrieve goals as a string\n",
        "    to_prove_pp = goals_to_str(goals)\n",
        "    # Gemma3 seems to prefer natural language instead of weird logician symbols\n",
        "    to_prove = to_prove_pp.replace('|-', 'to prove: ')\n",
        "\n",
        "    prompt = prompt.format(goal=to_prove)\n",
        "    output = get_response(prompt)\n",
        "    next_tactic = parse_output(output)\n",
        "    try:\n",
        "      # send tactic to Rocq proof assistant\n",
        "      state, goals = client.run_tac(state, next_tactic)\n",
        "      tactics.append(next_tactic)\n",
        "    except Exception as e:\n",
        "      # ignore tactics if failed\n",
        "      pass\n",
        "    if not goals:\n",
        "      # proof finished\n",
        "      print(\"Finished!\")\n",
        "      print(\"Found solution:\\n\" + \"\\n\".join(tactics) + \"\\n\\n\")\n",
        "      break\n",
        "  if goals:\n",
        "    print(\"Failed\" + \"\\n\\n\")\n",
        "  print()\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You may try to improve the prompt.\n",
        "\n",
        "In the following cell, there is a prompt with an explanation of some tactics in Rocq.\n",
        "Complete it and try it to see if it makes any difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"You are an expert in Coq, a theorem-proving assistant. Your task is to help progress a formal proof by providing exactly one correct and effective Coq tactic to advance towards the goal.\n",
        "\n",
        "Here is a brief explanation of tactics you may use:\n",
        "\n",
        "- intros: Introduces hypotheses or variables into the context. (example: \"intros P Q.\" introduces hypotheses P and Q.)\n",
        "- apply: Applies a hypothesis or theorem to match the current goal. (example: \"apply H0.\" If the goal is Q and you have a hypothesis H0: P -> Q, applying H0 changes the goal to P.)\n",
        "- exact: Directly solves the current goal if you have an exact matching hypothesis. (example: \"exact H.\" If the goal is P and you have a hypothesis H: P, then the goal is resolved.)\n",
        "- contradiction: Resolves the goal if there is a contradiction in the hypotheses. (example: if you have hypotheses H1: P -> False and H2: P, using \"contradiction.\" resolves the goal.)\n",
        "- unfold not: Expands the definition of negation (~P becomes P -> False). (examples: \"unfold not in H.\" applies it to hypothesis H, \"unfold not.\" applies it to the goal.)\n",
        "- inversion: Breaks apart hypotheses involving conjunctions (and), disjunctions (or), or existential quantifiers to reveal simpler components. (example: \"inversion H.\" breaks hypothesis H into simpler parts.)\n",
        "- split: Splits goals involving conjunctions into separate subgoals. (example: \"split.\" transforms goal P /\\ Q into two separate goals, P and Q.)\n",
        "- left/right: Selects a side of a disjunction (or) goal to prove. (examples: \"left.\" to prove the left side of a goal P \\/ Q, \"right.\" to prove the right side.)\n",
        "\n",
        "Current proof state:\n",
        "{goal}\n",
        "\n",
        "Carefully analyze the current goal, consider available hypotheses, and propose the most logical and efficient next step in the proof.\n",
        "\n",
        "Respond with ONLY ONE Coq tactic enclosed in a Coq code block. Ensure the tactic is syntactically correct and directly applicable. Don't write any comment, simple the code block.\n",
        "\n",
        "Example of correct formatting:\n",
        "```coq\n",
        "tactic_1.\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "for idx in range(client.num_thm('logic')):\n",
        "  # iterate over all theorems in the section 'logic'\n",
        "\n",
        "  print(f\"Try to prove theorem {idx}\")\n",
        "  state, goals = client.start_thm(\"logic\", idx)\n",
        "  tactics = []\n",
        "  for _ in tqdm(range(25)):\n",
        "\n",
        "    # retrieve goals as a string\n",
        "    to_prove_pp = goals_to_str(goals)\n",
        "    # Gemma3 seems to prefer natural language instead of weird logician symbols\n",
        "    to_prove = to_prove_pp.replace('|-', 'to prove: ')\n",
        "\n",
        "    prompt = prompt_template.format(goal=to_prove)\n",
        "    output = get_response(prompt)\n",
        "    next_tactic = parse_output(output)\n",
        "\n",
        "    try:\n",
        "      # send tactic to Rocq proof assistant\n",
        "      state, goals = client.run_tac(state, next_tactic)\n",
        "      tactics.append(next_tactic)\n",
        "    except Exception as e:\n",
        "      # ignore tactics if failed\n",
        "      pass\n",
        "    if not goals:\n",
        "      # proof finished\n",
        "      print(\"Finished!\")\n",
        "      print(\"Found solution:\\n\" + \"\\n\".join(tactics) + \"\\n\\n\")\n",
        "      break\n",
        "  if goals:\n",
        "    print(\"Failed\" + \"\\n\\n\")\n",
        "  print()\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You could try the following strategies:\n",
        "- Increase the number of tries.\n",
        "- Add some examples of lemma + proof in your prompt (few-shot prompting).\n",
        "\n",
        "If you feel confident enough, you could try to improve the overall strategy:\n",
        "- What would happen if you keep track of the wrong step in your prompt? (i.e. the one that throws an error)\n",
        "- What would happen if you keep track of redundant steps?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find a better strategy/prompt!\n",
        "\n",
        "# TO DO "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are able to prove most exercises from the \"logic\" section, maybe you can try to prove Lelarge's theorem? (section 'introduction', index 0)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following cell, you will find a partial implementation that is a bit better (keeps track of errors, redundant tactics, and increase number of tries).\n",
        "\n",
        "Try to complete it or improve it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "prompt_template = \"\"\"You are an expert in Coq, a theorem-proving assistant. Your task is to help progress a formal proof by providing exactly one correct and effective Coq tactic to advance towards the goal.\n",
        "\n",
        "Here is a brief explanation of tactics you may use:\n",
        "\n",
        "- intros: Introduces hypotheses or variables into the context. (example: \"intros P Q.\" introduces hypotheses P and Q.)\n",
        "- apply: Applies a hypothesis or theorem to match the current goal. (example: \"apply H0.\" If the goal is Q and you have a hypothesis H0: P -> Q, applying H0 changes the goal to P.)\n",
        "- exact: Directly solves the current goal if you have an exact matching hypothesis. (example: \"exact H.\" If the goal is P and you have a hypothesis H: P, then the goal is resolved.)\n",
        "- contradiction: Resolves the goal if there is a contradiction in the hypotheses. (example: if you have hypotheses H1: P -> False and H2: P, using \"contradiction.\" resolves the goal.)\n",
        "- unfold not: Expands the definition of negation (~P becomes P -> False). (examples: \"unfold not in H.\" applies it to hypothesis H, \"unfold not.\" applies it to the goal.)\n",
        "- inversion: Breaks apart hypotheses involving conjunctions (and), disjunctions (or), or existential quantifiers to reveal simpler components. (example: \"inversion H.\" breaks hypothesis H into simpler parts.)\n",
        "- split: Splits goals involving conjunctions into separate subgoals. (example: \"split.\" transforms goal P /\\ Q into two separate goals, P and Q.)\n",
        "- left/right: Selects a side of a disjunction (or) goal to prove. (examples: \"left.\" to prove the left side of a goal P \\/ Q, \"right.\" to prove the right side.)\n",
        "\n",
        "Current proof state:\n",
        "{goal}\n",
        "\n",
        "Carefully analyze the current goal, consider available hypotheses, and propose the most logical and efficient next step in the proof.\n",
        "\n",
        "Respond with ONLY ONE Coq tactic enclosed in a Coq code block. Ensure the tactic is syntactically correct and directly applicable. Don't write any comment, simple the code block.\n",
        "\n",
        "Example of correct formatting:\n",
        "```coq\n",
        "tactic_1.\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "prompt_remove = \"\"\"Don't use any of the following instructions:\n",
        "{remove}\n",
        "\"\"\"\n",
        "\n",
        "success = False\n",
        "for idx in range(client.num_thm('logic')):\n",
        "  # iterate over all theorems in the section 'logic'\n",
        "\n",
        "  print(f\"Try to prove theorem {idx}\")\n",
        "  state, goals = client.start_thm(\"logic\", idx)\n",
        "  tactics = []\n",
        "\n",
        "  # useless_tactics and failed_tactics keep track of errors and redundant tactics\n",
        "  useless_tactics = defaultdict(list)\n",
        "  failed_tactics = defaultdict(list)\n",
        "  for _ in tqdm(range(40)):\n",
        "    to_prove_pp = goals_to_str(goals)\n",
        "    to_prove = to_prove_pp.replace('|-', 'to prove: ')\n",
        "\n",
        "    bad_tactics = useless_tactics[to_prove_pp] + failed_tactics[to_prove_pp]\n",
        "    prompt = prompt_template.format(goal=to_prove)\n",
        "    prompt += prompt_remove.format(remove=\"\\n\".join(bad_tactics))\n",
        "    \n",
        "    output = get_response(prompt)\n",
        "    next_tactic = parse_output(output)\n",
        "    try:\n",
        "      state, goals = client.run_tac(state, next_tactic)\n",
        "      new_to_prove_pp = goals_to_str(goals)\n",
        "\n",
        "      # if goal doesn't change, add next_tactic to useless_tactics\n",
        "      if to_prove_pp == new_to_prove_pp:\n",
        "        useless_tactics[new_to_prove_pp].append(next_tactic)\n",
        "      tactics.append(next_tactic)\n",
        "    except Exception as e:\n",
        "      # if tactic fails, add next_tactic to failed_tactics\n",
        "      failed_tactics[to_prove_pp].append(next_tactic)\n",
        "      pass\n",
        "\n",
        "    if not goals:\n",
        "      print(\"Finished!\")\n",
        "      print(\"Found solution:\\n\" + \"\\n\".join(tactics))\n",
        "      break\n",
        "  if goals:\n",
        "    print(\"Failed\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specialized open-weight model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's download [ProofWala](https://arxiv.org/abs/2502.04671), a fine-tuned version of the [Code T5](https://arxiv.org/abs/2109.00859) model on a dataset of Lean and Rocq proofs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from transformers import pipeline\n",
        "from functools import partial\n",
        "from utils import generate_tactics_wala\n",
        "\n",
        "model_name = \"amitayusht/ProofWala-Multilingual\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0) # device=0 for GPU, -1 for CPU\n",
        "\n",
        "generate_tactics = partial(generate_tactics_wala, pipeline, model, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Naive strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's try this new model on the previous lemmas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for idx in range(client.num_thm('logic')):\n",
        "  # iterate over all theorems in the section 'logic'\n",
        "  print(f\"Try to prove theorem {idx}\")\n",
        "  state, goals = client.start_thm(\"logic\", idx)\n",
        "\n",
        "  # keep track of previous steps and incorrect steps\n",
        "  steps = []\n",
        "  incorrect_steps = []\n",
        "  for _ in tqdm(range(100)):\n",
        "    # generate 1 candidate for the next step associated to goals, and given previous steps and incorrect_steps\n",
        "    tactics, _ = generate_tactics(1, goals, steps=steps, incorrect_steps=incorrect_steps)\n",
        "    # tactics is a list of size 1\n",
        "    next_tactic = tactics[0]\n",
        "    try:\n",
        "      state, goals = client.run_tac(state, next_tactic)\n",
        "      steps.append(next_tactic)\n",
        "\n",
        "      # reset incorrect steps since goal may have change.\n",
        "      incorrect_steps = []\n",
        "    except Exception as e:\n",
        "      incorrect_steps.append(next_tactic)\n",
        "      pass\n",
        "    if not goals:\n",
        "      print(\"Finished!\")\n",
        "      print(\"Found solution:\\n\" + \"\\n\".join(steps) + \"\\n\\n\")\n",
        "      break\n",
        "  if goals:\n",
        "    print(\"Failed\" + \"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Beam Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this setup, we use an LLM to generate a sequence of steps.\n",
        "Unlike typical token-wise beam search, our approach operates step-wise scoring each entire step by its mean log probability.\n",
        "\n",
        "how it works (k-beam search):\n",
        "\n",
        "1. **Initialization:**  \n",
        "   Begin with a `<START>` step.\n",
        "\n",
        "2. **Step-wise Expansion:**  \n",
        "   At each iteration, expand each candidate sequence by generating full steps (each representing a complete Rocq step) and compute the mean log probability of the step.\n",
        "\n",
        "3. **Pruning:**  \n",
        "   Retain only the top-k candidates (according to their mean log probability) for further expansion.\n",
        "\n",
        "4. **Termination:**  \n",
        "   Continue until the `<END>` step is reached or a maximum number of steps is generated.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![beam_search](https://raw.githubusercontent.com/theostos/small-pytanque-tp/refs/heads/main/img/beam_search.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, what would happen with a beam search (step-wise)? Let's try it on our whole collection of exercises."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import beam_search\n",
        "\n",
        "for section in ['introduction', 'logic', 'math']:\n",
        "    for idx_thm in range(client.num_thm(section)):\n",
        "        print(f\"Trying to prove theorem {idx_thm} in section {section}.\")\n",
        "        found = False\n",
        "        for _ in tqdm(range(30)):\n",
        "            result = beam_search(generate_tactics, client, section, idx_thm, max_depth=7, beam_size=32, timeout=60)\n",
        "            if result:\n",
        "                print(\"Found solution:\\n\" + \"\\n\".join(result) + \"\\n\\n\")\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            print(\"Failed\" + \"\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "flask_new",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
